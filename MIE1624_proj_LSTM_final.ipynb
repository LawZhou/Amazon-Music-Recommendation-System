{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIE1624_proj_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1tfVIEKidRbuXtS6xZ8Ro-yQHkRPRj8tg",
      "authorship_tag": "ABX9TyOCWiK02DMr+Qk0LJCQOxnb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jackychencw/MIE1624_Course_Project_Group19/blob/Lawrence-nlp-preprocess/MIE1624_proj_LSTM_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv6LKYOsL4Y5",
        "outputId": "50e4355c-ed71-4410-cffc-9edce08ff0ec"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Reshape\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from keras.optimizers.schedules import ExponentialDecay\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import TransformerMixin\n",
        "\n",
        "from joblib import dump, load\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data/jacky_train_data.csv\", index_col=0)\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/data/jacky_test_data.csv\", index_col=0)\n",
        "rating_pairs_path = \"/content/drive/MyDrive/Colab Notebooks/data/rating_pairs.csv\"\n",
        "rating_pred_export_path = \"/content/drive/MyDrive/Colab Notebooks/data/rating_pairs_pred.csv\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TFJupZWAIOn"
      },
      "source": [
        "# Data preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Yzx0taL-ERJ"
      },
      "source": [
        "def clean_data(data):\n",
        "  data = data.drop(columns=[\n",
        "                   'reviewerID', 'reviewText', 'unixReviewTime', 'itemID', 'reviewHash', 'important_features'])\n",
        "  data['reviewTime'] = data.reviewTime.apply(lambda _: int(_[-4:]))\n",
        "  dummy_years = pd.get_dummies(data.reviewTime, prefix='year')\n",
        "  data = pd.concat([data, dummy_years], axis=1)\n",
        "  data = data.drop(columns=['reviewTime'])\n",
        "  return data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvyfywti-qJS"
      },
      "source": [
        "data = clean_data(data)\n",
        "test_data = clean_data(test_data)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvpoznQiAO-l"
      },
      "source": [
        "# Split training data into training set and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1oPxSqQtX20"
      },
      "source": [
        "saved_features = 2000 # max feature\n",
        "\n",
        "y = data.overall\n",
        "X = data.drop(columns=['overall'])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JNLo3iY-_lb"
      },
      "source": [
        "test_data = test_data.reindex(columns=X.columns)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACgVKCtNAZGx"
      },
      "source": [
        "# Neural Network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcUKxa51EGCL"
      },
      "source": [
        "We use a pipeline for our neural network model and it consists following steps: \n",
        "\n",
        "1.   The model uses column transformer to process the features separately. It normalizes the numeric features and vectorizes the text feature using TFIDF. We also use feature selection to select the best features for the text features.\n",
        "2.   It transforms the sparse matrix produced by the column transformer to dense matrix in order to feed in the neural network.\n",
        "3. The NN consists of a LSTM along with a few more dense layers and we use it to predict the overall rating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzLdz_CkP-nW"
      },
      "source": [
        "class DenseTransformer(TransformerMixin):\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None, **fit_params):\n",
        "        return X.todense()\n",
        "        \n",
        "def create_model(num_layer=256, \n",
        "                 init_lr=0.005, \n",
        "                 decay_rate=0.95, \n",
        "                 decay_step=3000, \n",
        "                 drop_out=0.75,\n",
        "                 epoch=50,\n",
        "                 batch_size=64):\n",
        "  def model_compiler(\n",
        "      num_layer=num_layer,\n",
        "      init_lr=init_lr,\n",
        "      decay_rate=decay_rate,\n",
        "      decay_steps=decay_step,\n",
        "      drop_out=drop_out,\n",
        "      loss_func='mse',\n",
        "      metrics = [tf.keras.losses.MSE]\n",
        "      ):\n",
        "    model = tf.keras.Sequential([\n",
        "      Reshape(target_shape=(1,-1)),\n",
        "      LSTM(num_layer),\n",
        "      Dropout(drop_out),\n",
        "      Dense(num_layer*2, kernel_initializer='normal', activation='relu'),\n",
        "      Dropout(drop_out),\n",
        "      Dense(num_layer, kernel_initializer='normal', activation='relu'),\n",
        "      Dropout(drop_out),\n",
        "      Dense(num_layer/2, kernel_initializer='normal', activation='relu'),\n",
        "      Dropout(drop_out),\n",
        "      Dense(1, kernel_initializer='normal', activation='relu')\n",
        "    ])\n",
        "    # decay learning rate\n",
        "    lr_schedule = ExponentialDecay(\n",
        "        initial_learning_rate=init_lr,\n",
        "        decay_steps=decay_steps,\n",
        "        decay_rate=decay_rate,\n",
        "        staircase=True)\n",
        "\n",
        "    opt = Adam(learning_rate=lr_schedule)\n",
        "    model.compile(loss=loss_func, optimizer=opt, metrics=metrics)\n",
        "    return model\n",
        "\n",
        "  vectorizers = {\n",
        "      'tfidf': TfidfVectorizer(),\n",
        "      }\n",
        "  summary_pipe = Pipeline([\n",
        "                      ('vect', TfidfVectorizer()),\n",
        "                      ('select', SelectKBest(chi2, k=saved_features))\n",
        "                      ])\n",
        "\n",
        "  review_pipe = Pipeline([('vect', TfidfVectorizer()),\n",
        "                          ('select', SelectKBest(chi2, k=saved_features))\n",
        "                                ])\n",
        "\n",
        "  preprocess = ColumnTransformer([\n",
        "                                ('price_std', StandardScaler(), ['price']),\n",
        "                                ('summary_count_vec', summary_pipe, 'summary'),\n",
        "                                ('review_tfidf', review_pipe, 'important_features(clean)')\n",
        "                                ], remainder = 'passthrough')\n",
        "  model = KerasRegressor(model_compiler, epochs=epoch, batch_size=batch_size, verbose=True)\n",
        "  pipe = Pipeline([('preprocess', preprocess),\n",
        "                    ('to_dense', DenseTransformer()),\n",
        "                    ('nn', model)], verbose=True)\n",
        "  return pipe\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzBCj-bueQ3K"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "class ModelTuner():\n",
        "  def __init__(self, params):\n",
        "    self.params = params\n",
        "    self.models = [create_model(**param, epoch=15) for param in self.params]\n",
        "    self.train_scores = [0] * len(self.params)\n",
        "    self.test_scores = [0] * len(self.params)\n",
        "\n",
        "  def fit_scores(self, X_train, y_train, X_test, y_test):\n",
        "    for i, model in enumerate(self.models):\n",
        "      model.fit(X_train, y_train)\n",
        "      y_train_pred = model.predict(X_train)\n",
        "      y_pred = model.predict(X_test)\n",
        "      self.test_scores[i] = mean_squared_error(y_test, y_pred)\n",
        "      self.train_scores[i] = mean_squared_error(y_train, y_train_pred)\n",
        "  \n",
        "  def visualize(self, title, xlabel):\n",
        "    width = 0.35  # the width of the bars\n",
        "    x = np.arange(len(self.train_scores))\n",
        "    params = [list(param.values())[0] for param in self.params]\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    rects1 = ax.bar(x - width/2, self.train_scores, width, label='Train')\n",
        "    rects2 = ax.bar(x + width/2, self.test_scores, width, label='Test')\n",
        "\n",
        "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
        "    ax.set_ylabel('MSE')\n",
        "    ax.set_title(title)\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(params)\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G975UsfPq69l"
      },
      "source": [
        "Tune initial learning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqpa1pI4nFSa",
        "outputId": "f52a013a-d72e-455b-90cb-1032cb2eb0f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "lr_tuner = ModelTuner(params=[{'init_lr': 0.05},\n",
        "                              {'init_lr': 0.01},\n",
        "                              {'init_lr': 0.005}\n",
        "                              ])\n",
        "lr_tuner.fit_scores(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ........ (step 1 of 3) Processing preprocess, total=   9.6s\n",
            "[Pipeline] .......... (step 2 of 3) Processing to_dense, total=   0.6s\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 17.4449 - mean_squared_error: 17.4449\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 798.9627 - mean_squared_error: 798.9627\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2641.8015 - mean_squared_error: 2641.8015\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 848.4644 - mean_squared_error: 848.4644\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2222.5879 - mean_squared_error: 2222.5879\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 13.9881 - mean_squared_error: 13.9881\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 4.6323 - mean_squared_error: 4.6323\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 4.6797 - mean_squared_error: 4.6797\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 34.8478 - mean_squared_error: 34.8478\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 3.6624 - mean_squared_error: 3.6624\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 3.5835 - mean_squared_error: 3.5835\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 447.7466 - mean_squared_error: 447.7466\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 48232.6467 - mean_squared_error: 48232.6467\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2.1128 - mean_squared_error: 2.1128\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 6276.2859 - mean_squared_error: 6276.2859\n",
            "[Pipeline] ................ (step 3 of 3) Processing nn, total= 1.8min\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            "469/469 [==============================] - 2s 2ms/step\n",
            "[Pipeline] ........ (step 1 of 3) Processing preprocess, total=   9.3s\n",
            "[Pipeline] .......... (step 2 of 3) Processing to_dense, total=   0.6s\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 2.4227 - mean_squared_error: 2.4227\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.8525 - mean_squared_error: 0.8525\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.9180 - mean_squared_error: 0.9180\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.9257 - mean_squared_error: 0.9257\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.9611 - mean_squared_error: 0.9611\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.9567 - mean_squared_error: 0.9567\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.9680 - mean_squared_error: 0.9680\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.9854 - mean_squared_error: 0.9854\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.9990 - mean_squared_error: 0.9990\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.9956 - mean_squared_error: 0.9956\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.0395 - mean_squared_error: 1.0395\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.9910 - mean_squared_error: 0.9910\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.9966 - mean_squared_error: 0.9966\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.0105 - mean_squared_error: 1.0105\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.0003 - mean_squared_error: 1.0003\n",
            "[Pipeline] ................ (step 3 of 3) Processing nn, total= 1.8min\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            "469/469 [==============================] - 2s 2ms/step\n",
            "[Pipeline] ........ (step 1 of 3) Processing preprocess, total=   9.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing to_dense, total=   0.6s\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 2.1774 - mean_squared_error: 2.1774\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6921 - mean_squared_error: 0.6921\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6569 - mean_squared_error: 0.6569\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6636 - mean_squared_error: 0.6636\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6593 - mean_squared_error: 0.6593\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6514 - mean_squared_error: 0.6514\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6292 - mean_squared_error: 0.6292\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6072 - mean_squared_error: 0.6072\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6072 - mean_squared_error: 0.6072\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5948 - mean_squared_error: 0.5948\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5837 - mean_squared_error: 0.5837\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5812 - mean_squared_error: 0.5812\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5817 - mean_squared_error: 0.5817\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5606 - mean_squared_error: 0.5606\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5581 - mean_squared_error: 0.5581\n",
            "[Pipeline] ................ (step 3 of 3) Processing nn, total= 1.8min\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            "469/469 [==============================] - 2s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyQwy3AkvrVM",
        "outputId": "37c07cac-2ea6-4250-edd2-1a1d20b17137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "lr_tuner.visualize(\"Initial learning rate VS MSE\", \"Initial learning rate\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGCNlUYT0iB_"
      },
      "source": [
        "# Delete the model to free memory\n",
        "del lr_tuner"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs_FeAUirDX-"
      },
      "source": [
        "Tune number of layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kz4nGhyrCNI",
        "outputId": "144e84d5-6b2a-45b3-c8fe-5ed665725591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "layer_tuner = ModelTuner(params=[{'num_layer': 128},\n",
        "                                 {'num_layer': 256},\n",
        "                                 {'num_layer': 324}\n",
        "                                ])\n",
        "layer_tuner.fit_scores(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ........ (step 1 of 3) Processing preprocess, total=   9.3s\n",
            "[Pipeline] .......... (step 2 of 3) Processing to_dense, total=   0.6s\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 2.5170 - mean_squared_error: 2.5170\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.7089 - mean_squared_error: 0.7089\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6423 - mean_squared_error: 0.6423\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6219 - mean_squared_error: 0.6219\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6056 - mean_squared_error: 0.6056\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6050 - mean_squared_error: 0.6050\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5858 - mean_squared_error: 0.5858\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5776 - mean_squared_error: 0.5776\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5717 - mean_squared_error: 0.5717\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5650 - mean_squared_error: 0.5650\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5518 - mean_squared_error: 0.5518\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5570 - mean_squared_error: 0.5570\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5356 - mean_squared_error: 0.5356\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5407 - mean_squared_error: 0.5407\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5338 - mean_squared_error: 0.5338\n",
            "[Pipeline] ................ (step 3 of 3) Processing nn, total= 1.8min\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            "469/469 [==============================] - 2s 2ms/step\n",
            "[Pipeline] ........ (step 1 of 3) Processing preprocess, total=   9.2s\n",
            "[Pipeline] .......... (step 2 of 3) Processing to_dense, total=   0.6s\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 2.2689 - mean_squared_error: 2.2689\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6927 - mean_squared_error: 0.6927\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6690 - mean_squared_error: 0.6690\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6682 - mean_squared_error: 0.6682\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6626 - mean_squared_error: 0.6626\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6500 - mean_squared_error: 0.6500\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6175 - mean_squared_error: 0.6175\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6310 - mean_squared_error: 0.6310\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6303 - mean_squared_error: 0.6303\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5894 - mean_squared_error: 0.5894\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5800 - mean_squared_error: 0.5800\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5700 - mean_squared_error: 0.5700\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5626 - mean_squared_error: 0.5626\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5564 - mean_squared_error: 0.5564\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5590 - mean_squared_error: 0.5590\n",
            "[Pipeline] ................ (step 3 of 3) Processing nn, total= 1.8min\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            "469/469 [==============================] - 2s 2ms/step\n",
            "[Pipeline] ........ (step 1 of 3) Processing preprocess, total=   9.2s\n",
            "[Pipeline] .......... (step 2 of 3) Processing to_dense, total=   0.6s\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 2.1869 - mean_squared_error: 2.1869\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.7074 - mean_squared_error: 0.7074\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.7018 - mean_squared_error: 0.7018\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.7114 - mean_squared_error: 0.7114\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.7151 - mean_squared_error: 0.7151\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6842 - mean_squared_error: 0.6842\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.6813 - mean_squared_error: 0.6813\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6810 - mean_squared_error: 0.6810\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6641 - mean_squared_error: 0.6641\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6705 - mean_squared_error: 0.6705\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6449 - mean_squared_error: 0.6449\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6369 - mean_squared_error: 0.6369\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6258 - mean_squared_error: 0.6258\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6191 - mean_squared_error: 0.6191\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6090 - mean_squared_error: 0.6090\n",
            "[Pipeline] ................ (step 3 of 3) Processing nn, total= 1.9min\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            "469/469 [==============================] - 2s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3jZqSV8voRc",
        "outputId": "22996cd0-4a9f-4008-bfb9-a61245cd9b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "layer_tuner.visualize(\"Number of Layers VS MSE\", \"Num of layers\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbFjzgov2luq"
      },
      "source": [
        "del layer_tuner"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhzZv1iUrUKh"
      },
      "source": [
        "Tune batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5DvxhRPnvaK",
        "outputId": "b24c8f96-4d1a-4b42-8f51-718835d05652",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_tuner = ModelTuner(params=[{'batch_size': 32},\n",
        "                                 {'batch_size': 64},\n",
        "                                 {'batch_size': 128}\n",
        "                                ])\n",
        "batch_tuner.fit_scores(X_train, y_train, X_test, y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ........ (step 1 of 3) Processing preprocess, total=   8.8s\n",
            "[Pipeline] .......... (step 2 of 3) Processing to_dense, total=   0.9s\n",
            "Epoch 1/15\n",
            "3750/3750 [==============================] - 15s 4ms/step - loss: 1.9135 - mean_squared_error: 1.9135\n",
            "Epoch 2/15\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.7511 - mean_squared_error: 0.7511\n",
            "Epoch 3/15\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.7383 - mean_squared_error: 0.7383\n",
            "Epoch 4/15\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.7250 - mean_squared_error: 0.7250\n",
            "Epoch 5/15\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.7451 - mean_squared_error: 0.7451\n",
            "Epoch 6/15\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.7472 - mean_squared_error: 0.7472\n",
            "Epoch 7/15\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.7188 - mean_squared_error: 0.7188\n",
            "Epoch 8/15\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.7144 - mean_squared_error: 0.7144\n",
            "Epoch 9/15\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.7049 - mean_squared_error: 0.7049\n",
            "Epoch 10/15\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.6913 - mean_squared_error: 0.6913\n",
            "Epoch 11/15\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.7062 - mean_squared_error: 0.7062\n",
            "Epoch 12/15\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.6707 - mean_squared_error: 0.6707\n",
            "Epoch 13/15\n",
            "3750/3750 [==============================] - 13s 4ms/step - loss: 0.6462 - mean_squared_error: 0.6462\n",
            "Epoch 14/15\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.6550 - mean_squared_error: 0.6550\n",
            "Epoch 15/15\n",
            "3750/3750 [==============================] - 14s 4ms/step - loss: 0.6412 - mean_squared_error: 0.6412\n",
            "[Pipeline] ................ (step 3 of 3) Processing nn, total= 3.4min\n",
            "3750/3750 [==============================] - 8s 2ms/step\n",
            "938/938 [==============================] - 3s 2ms/step\n",
            "[Pipeline] ........ (step 1 of 3) Processing preprocess, total=   9.2s\n",
            "[Pipeline] .......... (step 2 of 3) Processing to_dense, total=   0.9s\n",
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 2.3002 - mean_squared_error: 2.3002\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6940 - mean_squared_error: 0.6940\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6571 - mean_squared_error: 0.6571\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6606 - mean_squared_error: 0.6606\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6535 - mean_squared_error: 0.6535\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6477 - mean_squared_error: 0.6477\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6364 - mean_squared_error: 0.6364\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6251 - mean_squared_error: 0.6251\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6100 - mean_squared_error: 0.6100\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5983 - mean_squared_error: 0.5983\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5757 - mean_squared_error: 0.5757\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5816 - mean_squared_error: 0.5816\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5611 - mean_squared_error: 0.5611\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5544 - mean_squared_error: 0.5544\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5597 - mean_squared_error: 0.5597\n",
            "[Pipeline] ................ (step 3 of 3) Processing nn, total= 1.8min\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            "469/469 [==============================] - 2s 2ms/step\n",
            "[Pipeline] ........ (step 1 of 3) Processing preprocess, total=   8.7s\n",
            "[Pipeline] .......... (step 2 of 3) Processing to_dense, total=   0.9s\n",
            "Epoch 1/15\n",
            "938/938 [==============================] - 6s 5ms/step - loss: 2.5111 - mean_squared_error: 2.5111\n",
            "Epoch 2/15\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.8284 - mean_squared_error: 0.8284\n",
            "Epoch 3/15\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.6256 - mean_squared_error: 0.6256\n",
            "Epoch 4/15\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.5823 - mean_squared_error: 0.5823\n",
            "Epoch 5/15\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.5663 - mean_squared_error: 0.5663\n",
            "Epoch 6/15\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.5573 - mean_squared_error: 0.5573\n",
            "Epoch 7/15\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.5630 - mean_squared_error: 0.5630\n",
            "Epoch 8/15\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.5615 - mean_squared_error: 0.5615\n",
            "Epoch 9/15\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.5498 - mean_squared_error: 0.5498\n",
            "Epoch 10/15\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.5355 - mean_squared_error: 0.5355\n",
            "Epoch 11/15\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.5413 - mean_squared_error: 0.5413\n",
            "Epoch 12/15\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.5426 - mean_squared_error: 0.5426\n",
            "Epoch 13/15\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.5466 - mean_squared_error: 0.5466\n",
            "Epoch 14/15\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.5290 - mean_squared_error: 0.5290\n",
            "Epoch 15/15\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.5274 - mean_squared_error: 0.5274\n",
            "[Pipeline] ................ (step 3 of 3) Processing nn, total= 1.2min\n",
            "938/938 [==============================] - 3s 3ms/step\n",
            "235/235 [==============================] - 1s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HDqGuPp2qWD",
        "outputId": "d7d04153-4f1d-466c-80c4-3f23f0557513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "batch_tuner.visualize(\"Batch size VS MSE\", \"Batch size\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPXwBTCMARLV"
      },
      "source": [
        "# Fit the model on partial training data and validate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iR5glU1vPdu"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "def model_test(model, X_test, y_test):\n",
        "  y_pred = model.predict(X_test)\n",
        "  score = mean_squared_error(y_test, y_pred)\n",
        "  return score"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgSMr9-eAZqe"
      },
      "source": [
        "pipe = create_model(batch_size=64, num_layer=256, init_lr=0.005)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ig1M3QzAfdi",
        "outputId": "e77d818c-e706-441e-cb98-453c40902650",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pipe.fit(X_train, y_train)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ........ (step 1 of 3) Processing preprocess, total=   9.1s\n",
            "[Pipeline] .......... (step 2 of 3) Processing to_dense, total=   1.9s\n",
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 2.2714 - mean_squared_error: 2.2714\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6920 - mean_squared_error: 0.6920\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6621 - mean_squared_error: 0.6621\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6669 - mean_squared_error: 0.6669\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6635 - mean_squared_error: 0.6635\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6308 - mean_squared_error: 0.6308\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6314 - mean_squared_error: 0.6314\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.6229 - mean_squared_error: 0.6229\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5905 - mean_squared_error: 0.5905\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5856 - mean_squared_error: 0.5856\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5709 - mean_squared_error: 0.5709\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5565 - mean_squared_error: 0.5565\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5565 - mean_squared_error: 0.5565\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5372 - mean_squared_error: 0.5372\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5364 - mean_squared_error: 0.5364\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5364 - mean_squared_error: 0.5364\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5171 - mean_squared_error: 0.5171\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5174 - mean_squared_error: 0.5174\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5147 - mean_squared_error: 0.5147\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5080 - mean_squared_error: 0.5080\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5145 - mean_squared_error: 0.5145\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4871 - mean_squared_error: 0.4871\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4913 - mean_squared_error: 0.4913\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4824 - mean_squared_error: 0.4824\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4856 - mean_squared_error: 0.4856\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4675 - mean_squared_error: 0.4675\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4687 - mean_squared_error: 0.4687\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4702 - mean_squared_error: 0.4702\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4691 - mean_squared_error: 0.4691\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4619 - mean_squared_error: 0.4619\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4630 - mean_squared_error: 0.4630\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4535 - mean_squared_error: 0.4535\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4573 - mean_squared_error: 0.4573\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4474 - mean_squared_error: 0.4474\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4481 - mean_squared_error: 0.4481\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4389 - mean_squared_error: 0.4389\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4402 - mean_squared_error: 0.4402\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4342 - mean_squared_error: 0.4342\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4356 - mean_squared_error: 0.4356\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4304 - mean_squared_error: 0.4304\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4326 - mean_squared_error: 0.4326\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4254 - mean_squared_error: 0.4254\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4271 - mean_squared_error: 0.4271\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4119 - mean_squared_error: 0.4119\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4147 - mean_squared_error: 0.4147\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4084 - mean_squared_error: 0.4084\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4121 - mean_squared_error: 0.4121\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4003 - mean_squared_error: 0.4003\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4082 - mean_squared_error: 0.4082\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4096 - mean_squared_error: 0.4096\n",
            "[Pipeline] ................ (step 3 of 3) Processing nn, total= 5.8min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('preprocess',\n",
              "                 ColumnTransformer(n_jobs=None, remainder='passthrough',\n",
              "                                   sparse_threshold=0.3,\n",
              "                                   transformer_weights=None,\n",
              "                                   transformers=[('price_std',\n",
              "                                                  StandardScaler(copy=True,\n",
              "                                                                 with_mean=True,\n",
              "                                                                 with_std=True),\n",
              "                                                  ['price']),\n",
              "                                                 ('summary_count_vec',\n",
              "                                                  Pipeline(memory=None,\n",
              "                                                           steps=[('vect',\n",
              "                                                                   TfidfVectorizer(analyzer='word',\n",
              "                                                                                   binary=False,\n",
              "                                                                                   decode_error=...\n",
              "                                                                                   tokenizer=None,\n",
              "                                                                                   use_idf=True,\n",
              "                                                                                   vocabulary=None)),\n",
              "                                                                  ('select',\n",
              "                                                                   SelectKBest(k=2000,\n",
              "                                                                               score_func=<function chi2 at 0x7fb7d73250e0>))],\n",
              "                                                           verbose=False),\n",
              "                                                  'important_features(clean)')],\n",
              "                                   verbose=False)),\n",
              "                ('to_dense',\n",
              "                 <__main__.DenseTransformer object at 0x7fb7d0cad190>),\n",
              "                ('nn',\n",
              "                 <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fb7d0cad5d0>)],\n",
              "         verbose=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-1wY5OuHbzL"
      },
      "source": [
        "As we can see, the model is still a bit overfitted although we already did feature selection, learning rate decay and hyperparameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "891dzu0vAj7D",
        "outputId": "81419dda-5f66-46fa-fd39-2b26eb28364e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_score = model_test(pipe, X_train, y_train)\n",
        "test_score = model_test(pipe, X_test, y_test)\n",
        "print(f\"Training MSE: {train_score}\")\n",
        "print(f'Testing MSE: {test_score}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 4s 2ms/step\n",
            "469/469 [==============================] - 2s 3ms/step\n",
            "Training MSE: 0.3104792462611851\n",
            "Testing MSE: 0.46910162884452317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_bz2tmSA8S4"
      },
      "source": [
        "# Fit the model on all training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL8cSFpw88dT"
      },
      "source": [
        "Train the model using all data with best hyperparameters:\n",
        "batch_size=64, num_layer=256, init_lr=0.005"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALuSCen8mLOr"
      },
      "source": [
        "pipe = create_model(batch_size=64, num_layer=256, init_lr=0.005)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD4SC0_41jCb",
        "outputId": "137f8fd1-c7a4-4b83-8ef3-9717963985ee"
      },
      "source": [
        "import numpy as np\n",
        "pipe.fit(X, y)\n",
        "predictions = pipe.predict(test_data)\n",
        "# clip the data between the range of the reviews\n",
        "predictions = np.clip(predictions, a_min=1.0, a_max=5.0)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Pipeline] ........ (step 1 of 3) Processing preprocess, total=  11.3s\n",
            "[Pipeline] .......... (step 2 of 3) Processing to_dense, total=   1.2s\n",
            "Epoch 1/50\n",
            "2344/2344 [==============================] - 12s 4ms/step - loss: 2.0779 - mean_squared_error: 2.0779\n",
            "Epoch 2/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.6724 - mean_squared_error: 0.6724\n",
            "Epoch 3/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.6579 - mean_squared_error: 0.6579\n",
            "Epoch 4/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.6694 - mean_squared_error: 0.6694\n",
            "Epoch 5/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.6561 - mean_squared_error: 0.6561\n",
            "Epoch 6/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.6501 - mean_squared_error: 0.6501\n",
            "Epoch 7/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.6364 - mean_squared_error: 0.6364\n",
            "Epoch 8/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.6254 - mean_squared_error: 0.6254\n",
            "Epoch 9/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.6124 - mean_squared_error: 0.6124\n",
            "Epoch 10/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.5913 - mean_squared_error: 0.5913\n",
            "Epoch 11/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.5772 - mean_squared_error: 0.5772\n",
            "Epoch 12/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.5675 - mean_squared_error: 0.5675\n",
            "Epoch 13/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.5509 - mean_squared_error: 0.5509\n",
            "Epoch 14/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.5449 - mean_squared_error: 0.5449\n",
            "Epoch 15/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.5421 - mean_squared_error: 0.5421\n",
            "Epoch 16/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.5279 - mean_squared_error: 0.5279\n",
            "Epoch 17/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.5228 - mean_squared_error: 0.5228\n",
            "Epoch 18/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.5286 - mean_squared_error: 0.5286\n",
            "Epoch 19/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.5065 - mean_squared_error: 0.5065\n",
            "Epoch 20/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.5394 - mean_squared_error: 0.5394\n",
            "Epoch 21/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.5072 - mean_squared_error: 0.5072\n",
            "Epoch 22/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4997 - mean_squared_error: 0.4997\n",
            "Epoch 23/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4906 - mean_squared_error: 0.4906\n",
            "Epoch 24/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4808 - mean_squared_error: 0.4808\n",
            "Epoch 25/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4814 - mean_squared_error: 0.4814\n",
            "Epoch 26/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4756 - mean_squared_error: 0.4756\n",
            "Epoch 27/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4715 - mean_squared_error: 0.4715\n",
            "Epoch 28/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4687 - mean_squared_error: 0.4687\n",
            "Epoch 29/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4618 - mean_squared_error: 0.4618\n",
            "Epoch 30/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4570 - mean_squared_error: 0.4570\n",
            "Epoch 31/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4582 - mean_squared_error: 0.4582\n",
            "Epoch 32/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4602 - mean_squared_error: 0.4602\n",
            "Epoch 33/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4455 - mean_squared_error: 0.4455\n",
            "Epoch 34/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4464 - mean_squared_error: 0.4464\n",
            "Epoch 35/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4371 - mean_squared_error: 0.4371\n",
            "Epoch 36/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4398 - mean_squared_error: 0.4398\n",
            "Epoch 37/50\n",
            "2344/2344 [==============================] - 11s 5ms/step - loss: 0.4327 - mean_squared_error: 0.4327\n",
            "Epoch 38/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4288 - mean_squared_error: 0.4288\n",
            "Epoch 39/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4201 - mean_squared_error: 0.4201\n",
            "Epoch 40/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4228 - mean_squared_error: 0.4228\n",
            "Epoch 41/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4238 - mean_squared_error: 0.4238\n",
            "Epoch 42/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4220 - mean_squared_error: 0.4220\n",
            "Epoch 43/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4138 - mean_squared_error: 0.4138\n",
            "Epoch 44/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4131 - mean_squared_error: 0.4131\n",
            "Epoch 45/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4070 - mean_squared_error: 0.4070\n",
            "Epoch 46/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4120 - mean_squared_error: 0.4120\n",
            "Epoch 47/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4060 - mean_squared_error: 0.4060\n",
            "Epoch 48/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4037 - mean_squared_error: 0.4037\n",
            "Epoch 49/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4004 - mean_squared_error: 0.4004\n",
            "Epoch 50/50\n",
            "2344/2344 [==============================] - 10s 4ms/step - loss: 0.4010 - mean_squared_error: 0.4010\n",
            "[Pipeline] ................ (step 3 of 3) Processing nn, total= 8.4min\n",
            "313/313 [==============================] - 1s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ofBzn1stM_o",
        "outputId": "1bcf6c21-0daa-407b-cbfa-75d782277f6b"
      },
      "source": [
        "score = model_test(pipe, X, y)\n",
        "print(f\"Training MSE: {score}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2344/2344 [==============================] - 5s 2ms/step\n",
            "Training MSE: 0.3195194428121786\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y53kjXmPzDV2"
      },
      "source": [
        "def export_to_kaggle(rating_pairs_path, predictions, export_path):\n",
        "  rating_pairs = pd.read_csv(rating_pairs_path)\n",
        "  rating_pairs['prediction'] = predictions\n",
        "  rating_pairs.to_csv(export_path, index=False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6x6x947zohJ"
      },
      "source": [
        "export_to_kaggle(rating_pairs_path, predictions, rating_pred_export_path)"
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}